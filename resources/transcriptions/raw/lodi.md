grazie grazie per l'invito Dicevo prima che ho scelto di venire qua in presenza quindi insomma perché avevo fatto questa cosa anche a Trieste e mi dispiace di avervi fatto cambiare anche il il programma Eh io oggi volevo cercare di eh qui parlare di questa occasione dei dati aperti Ho messo tra parentesi perché in realtà in generale io adesso mi occupo non solo dei dati aperti ma di dati a 360° e però secondo me a maggior ragione i dati aperti nell'era dell'intelligenza artificiale e cerchiamo di capire perché no E di solito quando faccio questa presentazione adesso dove ci si mette l'intelligenza artificiale perché sennò non sia nessuno nella vita ormai e ci metto sempre degli esempi con chat GPT per far capire ho scelto Chat GPT avrei potuto scegliere qualunque altro modello di intelligenza artificialeativa di ultima generazione per farvi capire un po' il il perché voglio arrivare a parare in un certo punto Allora ho chiesto a Chat GPT ho fatto due in realtà ho fatto due domande no Ho ho voluto cercare di capire se Chat GPT conosce qualcosa sui nostri beni culturali italiani G l'ho fatto in inglese perché meglio insomma no Perché poi lo sapete che con le lingue anche questo è un altro problema di questi LLM Ehm e gli ho chiesto il numero di siti diciamo che sono liberalmente accessibili nella regione Lazio una risposta piuttosto ampia e e argomentata diciamo e vabbè lì poi ti intornano e dice ve l'ho evidenziato in rosso che ci sono circa dai 200 ai 250 siti eh quindi luoghi della cultura nella regione Lazio che offrono un accesso libero sia permanentemente oppure in certi giorni specifici della settimana per esempio come può essere la prima domenica del testo Ok Questa risposta è interessante nel senso che per un utente normale ok è una risposta molto buona eh pera molto probabilmente Poi gli ho fatto un'altra domanda gli ho detto quanti posti a Milano sono classificati come gallerie d'arte e eh e lui mi ha detto che secondo i dati recenti insomma disponibili Milano ha circa dai 90 ai 100 posti classificati come galleria d'arte Ok Quindi anche questa risposta se vedete è abbastanza simile no E quindi ok però mi sono detta vabbè ma noi abbiamo i Linkedopa sei beni culturali italiani no E quindi perché non chiedere al Ministero della Cultura che li pubblica e tiene speranzosamente aggiornati le stesse identiche domande per vedere se il risultato è uguale Ehm e quindi l'ho chiesto ad Arco Arco è la rete no è il knowledge graph il grafo della conoscenza aperto dei bene italiani Fatto la prima naturalmente per chiederlo al knowledge graph devo fare delle qu sparkle Ok io un po' di Sparkle lo conosco magari non proprio tutti tutti però c'ho provato no E ho fatto una mia di Sparkle e alla prima domanda mi ha risposto 432 Mi ricordo che chat GPT aveva detto tra i 200 e 250 quindi in realtà sono il doppio Ok Eh più o meno E nella seconda domanda eh lui aveva risposto tra i 90 e i 100 in realtà sono 58 Mh Eh allora qui c'è qualcosa che non va Ok Eh questo per dirvi che attenzione ad usare quei software in un certo modo Vi dico anche perché è un po' che in certo GPT adesso c'ha la possibilità di abilitare la ricerca sul web Non l'avevo abilitata ho usato l'LM così come nasceva Ok quella funzionalità di andare a cercare un sito web è nato successivamente e non è una cosa intrinseca dell LM aggiuntiva che lui usa per aiutarsi a migliorare le sue risposte La cosa che sicuramente emerge è che queste risposte a volte sono sbagliate semplicemente cosiddette sbagliate Allora cosa abbiamo cercato di fare Anche nel nelle mie tante vesti e cappelli che ho tra socia di una spin-off del CNR laboratorio di ricerca ho detto "Vabbè ma scusatemi se io ho questi dati aperti così puntuali precisi aggiornati e quant'altro perché non li uso per fare in modo che certo GPT mi risponda in maniera puntuale?" ok Quindi cerco di mettere in piedi delle tecniche affinché gli LLM usino queste banche di dati strutturate per poter migliorare le sue risposte E infatti così abbiamo fatto Abbiamo cercato di mettere insieme chatt i dati aperti e se guardate la risposta adesso la risposta diventa corretta cioè lui ti risponde 432 esattamente com'è la FC e la stessa cosa capita con la dice 58 esattamente come è il risultato della quaris Ora che cosa ho fatto qua In realtà semplicemente ho detto agli LLM e quindi all'intelligenza artificiale generativa usa delle banche dati esterne per migliorare i tuoi risultati Questo perché Perché eh lo sappiamo o se non lo sappiamo adesso dobbiamo iniziare a capirlo per bene fino in fondo che ehm questi software di intelligenza artificiale producono quelle che vengono chiamate allucinazioni Allora è un termine lo dicevo anche recentemente sui social network che non mi piace l'allucinazione però tecnicamente ormai è il termine che si usa per indicare il fatto che è uno dei grossissimi problemi che producono risposte a volte che non sono vere ma sembrano verosimili cioè una persona che non sa niente di quello che vi ho raccontato finora si fida il 200 tra i 200 e 250 poi tra l'altro tra i 200 e 250 quindi c'è un range no e quindi è portato a fare questa cosa Io mi ricordo qualche boh forse l'anno scorso c'era un colloquio tra due ragazzi in autobus e che dicevano lei diceva lui "Ma perché non l'hai chiesto a chat GPT l'orario in cui passa là?" E io e volevi rispondere o no E io a parte che volevo rispondere ma vabbè ma disc però assurdo ma è stato secondo me il fatto di aver messo a disposizione lasciatemi dire alle masse dei software del genere che da un lato ha avuto dei dei secondo me degli aspetti stra positivi dall'altro lato ci sono degli aspetti negativi e bisogna stare attenti che ha subito di recente c'è stato un recente post ha pubblicato un articolo e che si intitolava Perché spesso Chat GPT si inventa le cose no per parlare appunto di queste vicinazioni e c'è un ricercatore del Politecnico di Milano Stefano Zanero non so se lo conoscete molto famoso nell'ambito della cyb security italiana che diceva guardate che loro non è che si spesso inventano le cose lo fanno sempre cioè è il loro modo operando perché loro semplicemente si basano su dei modelli matematici dietro statistici e vanno a vedere qual è la probabilità che una parola è seguita da un'altra parola Come fanno a fare questo hanno un corpus su cui sono stati addestrati dei dati in quel caso non strutturati perché la maggior parte è testo eh dove deducono attraverso tutta una serie di eh pesi che attribuiscono alle varie parole all'interno un certo riso Ed è impressionante a volte seriamente impressionante Così come è impressionante il fatto che nelle domande di prima se abilitate la ricerca sul web lui andava a cercare nel sito giusto ok noi un sito a caso ma proprio nel sito giusto per andare a trovare la risposta Quindi ci sono delle cose abbastanza impressive ok Però bisogna stare attenti perché appunto questo fenomeno è lì c'è dobbiamo tenerlo in considerazione dobbiamo essere consapevoli quando usiamo questi software che questo fenomeno c'è e dobbiamo lavorare per mitigare L'altro punto fondamentale secondo me di queste software è che sono delle scatole nere no nel senso che in realtà nessuno ancora è in grado di spiegare che cosa avviene là dentro nel senso che eh vi dicevo prima ci sono dei modelli statistici alla base di questi software ok è tutto basato su pesi eh che vengono attribuiti Se questi pesi tra l'altro non sono aperti quindi non sono open source per esempio è difficile riuscire a capire come lui si costruisce il suo modello perché fa questo in realtà in base al dato di input quindi tanto il dato di input cambia anche il modello dentro si può adattare e crea questo modello per produrre un risultato ma noi non lo sappiamo qual è effettivamente eh come ci arriva a produrre quel risultato E infatti spesso si dice che non si riesce a spiegare il perché mi ritorna quel risultato lì Pensate se non so nemmeno qual è il dato di input come posso arrivare a capire qual è il suo risultato finale no E altra caratteristica e questo è il grande tema di cui si accennava poco fack è che ignorano completamente questo è un po' l'uso anche che ne viene fatto da coloro che hanno sviluppato questi software che ignorano completamente qualunque tipo di vincolo che può esistere sul dato che sia esso strutturato o non strutturato Io dico sempre che fanno un po' do coio coio nel senso che fanno scraping sul web di qualunque pagina ok E attenzione usano molto e qua c'è uno studio in a livello UK che usano tantissimo i siti web del pubblico amministrazioni fanno scraping delle quelle informazioni quindi ragionate anche su questo Se il vostro sito web della pubblica amministrazione non è aggiornato pensate che cosa può venire fuori visto che già non producono risposte veritiere per definizione Ok e eh ignorano tutto questo tema Ed è un tema enorme seriamente enorme che secondo me ancora non è stato affrontato Tra l'altro il risultato che loro producono e chi è di proprietà intellettuale chi l'ha prodotto La la la macchina stessa o sono tutti gli input che lui mette insieme che producono questa cosa Cioè ci sono dei ragionamenti lì fuori nell'uso di questi software che noi dovremmo iniziare a fare e che secondo me adesso vi arrivo a sperare spero di convincervi gli Open Data possono essere un buon veicolo per cercare di tamponare questa situazione Infine non esistono se non ci sono dati ok Cioè non esiste intelligenza artificiale se non ci sono dati non non avrebbe nessun tipo di senso E il dato dipende fortemente dal dato di input per come vi dicevo prima per come sono tecnicamente fatti Quindi che cosa vuol dire questo che se quel dato non è completo per esempio il risultato non potrà mai essere completo Mi ricordo che c'era un esempio e spesso lo ricordo dell'uso dell'intelligenza artificiale nell'ambito della giustizia americana che poi è stato completamente vietato ad un certo punto perché era eclatante I dati di input erano la maggior parte delle volte sentenze contro persone di colore e quindi il risultato era sempre che si andava ad imputare una persona di colore magari forse il reato era stato commesso in quel caso da una persona invece eh bianca diciamo così Ecco questo per dirvi che attenzione perché se poi li usiamo per prendere delle delle decisioni che hanno un impatto sulla nostra vita diventa abbastanza eh problematico E allora io dico e qui riporto una cosa che dice in realtà non io eh perché ormai già stato tutto detto dell'Open Data Institute secondo me bisogna ripartire da questi principi Questo è stato pubblicato proprio non molto tempo fa da loro come una sorta di intenti diciamo così E ci sono due principi che mi hanno colpito nello specifico Il primo dice che ci vuole nell'era dell'intelligenza artificiale una strong data infrastructure ok Perché dobbiamo costruire un qualcosa che sia eh un ecosistema di dati di fiducia in un qualche modo e per costruirla dobbiamo tenere in considerazione di tutto lo spettro dei dati aperti dei dati Ok Tra l'altro questa figura che vedete qua è vecchissima Io tra l'altro insegno anche all'università ai miei studenti È una figura secondo me che veramente vi vi dice un po' tutto lo spettro dei dati guardando anche diverse dimensioni se sono piccoli medi grandi se sono personali commerciali o del governo del settore pubblico se sono chiusi se sono condivisi e se sono completamente aperti no Quindi per gestire tutto questo ok noi abbiamo bisogno di eh nell'era dell'intelligenza artificiale avere delle pratiche che mi consentono di gestire in maniera forte e dicono anche che la miglior possibile foundation quindi pilastro di tutto questo è il dato aperto E io perché dico ripartire da qua e da questa cosa Perché riprendiamo i problemi e i limiti che abbiamo visto prima no e come i dati aperti ci possono aiutare Allora allucinazioni vi ho portato un esempio pratico dove le allucinazioni erano lì però ho usato i dati aperti e ho migliorato i risultati Quindi eh in questo caso da un punto di vista tecnico ho usato una tecnica che si chiama Rag che si chiama retrievola augmented generation Sostanzialmente gli do una base di conoscenza ok Posso farlo anche con una banca dati che è completamente chiusa eh non è necessariamente aperto però eh ho usato questa tecnica per cercare di mitigare e ridurre l'effetto delle allucinazioni che i dati aperti sono uno strumento secondo me micidiale da questo punto di vista perché chiunque li può guardare coi dati aperti quindi chiunque si può anche riconoscere la qualità di quei dati ok Nel momento in cui noi ci apriamo e ci offriamo all'intelligenza collettiva ci apriamo anche alla possibilità di poter migliorare questi dati e questo non può che essere uno strumento fondamentale per cercare di litigare un fenomeno come quello dell'allucinazione Eh abbiamo detto che sono delle scatole nere no Quindi mi raccomando una cosa importante non fanno ragionamenti non hanno un'idea di conc di contesto di questo tipo Io a volte sento ah ma arrivano ad avere emozioni no No assolutamente no È tutta roba iper mega statistica ok Con modelli matematici molto spinti dietro ma non hanno queste capacità ok Eh perché qui dico che eh i dati aperti nel caso delle scatole nere potrebbero aiutare Intanto perché se ehm io potrei per esempio se uso dei dati aperti in input spiegare perché arrivo ad un certo risultato Qualche anno fa perché il mondo della ricerca siamo sempre un pochino più avanti ammetito c'è stata una bellissima presentazione di un forum insomma della comunità del semantic Web tra parentesi che faceva vedere come dato un knowledge graph ehm tra l'altro con delle immagini ok questi software potevano essere migliorati e si poteva spiegare come loro arrivavano a un certo risultato e come potevano arrivare a risultato stato corretto usando appunto strumenti di dati strutturati in un certo modo con una certa semantica e e che spiegano anche il significato dei dati Quindi l'explinability di questi software che è un altro tema di ricerca molto ampio potrebbe essere assolutamente indirizzato con la disponibilità di dati aperti riutilizzabili da chiunque perché i dati aperti possono essere anche proprio utilizzati per l'allenamento di questi software anche per il principio famoso di trasparenza che ce lo impone la IACT che sapete no che adesso chiamo questa norma europea che dice che i software di intelligenza artificiale devono essere classificati in base a un certo alto rischio e se sono di alto rischio perché hanno l'impatto e risultato sugli esseri umani devono rispettare condizioni di trasparenza Quindi per esempio dovreste dire quali sono i dataset su cui voi allenate il software ok Allora se sono i dati aperti tanto più è agevolato questo compito Eh ignorano i vincoli sui dati ma noi abbiamo i dati aperti I dati aperti non hanno vincoli se li hanno ce li hanno poco no e quindi forse riusciamo anche a mettere a posto un pochino questo aspetto legale enorme che loro hanno no Quindi perché no Perché non sfruttare questo fatto di avere di usare i dati aperti in questo senso Poi mi rendo conto che non è che tutti i dati sono esclusivamente dati aperti perché bisogna bilanciare ci sono anche dati personali e che devono essere trattati in un certo modo però c'è una grande fetta di dato che può essere dato aperto può essere utilizzato Infine abbiamo detto che senza i dati non esistono i dati aperti sono per definizione dei dati che dovrebbero dovrebbero dovrebbero avere un formato aperto e quindi machine ridable dovrebbero Ok e quindi a maggior ragione vuol dire accessibili disponibili no e quindi ci aiutano tantissimo per poter eh usare questi software Lasciatemi dire anche visto che ho una piccola società è una spin-off del CNR se ci fossero di più questi dati aperti di qualità non sarebbe male anche per noi perché sarebbe un vantaggio anche di competizione perché una società in miniatura come la nostra come fa a competere con Open AI Microsoft che c'ha tutto il mondo di o Google Ok è chiaro che non non riesce a competere Se invece abbiamo i dati aperti che mettono tutti nel riutilizzo allo stesso piano è chiaro che pure io posso fare qualcosa Ehm quindi ritornando sempre all'operdata Institute i dati aperti potrebbero diventare veramente l'infrastruttura ideale per l'allenamento di questi software di intelligenza artificiale E loro guardate che cosa dicono qua tra parentesi dicono che quando cioè che un dato che è pronto per l'addestramento all'intelligenza artificiale significa in pratica eh applicare diverse pratiche tra cui la fa ok Findable accessible intero per usable e non solo per i dati della ricerca tutti i radit data Ok linkeda ok E qui vabbè torna un po' la mia battaglia nazionale insomma diciamo così perché perché perché i data sono dati collegati ad altri dati per definizione con una semantica e quindi possono avere tutti quei vantaggi che vi dicevo precedentemente E dicono anche che nel creare dati aperti bisogna avere in mente queste potenzialità dei software di intelligenza artificiale cioè dicono guardate che il governo dovrebbe garantire che in un qualche modo pubblica dei dati di alta qualità secondo tutte quelle buone pratiche proprio per evitare che magari questi software vadano a a cercare dei dati insorgenti secondarie magari non autoritative come nel caso del governo proprio per dare un risultato migliore e soprattutto quando si parla di intelligenza artificiale applicata per esempio ai servizi pubblici ok Senza affidarsi a X che scrive nel suo blog che quel servizio pubblico è fatto in questo modo Ok Eh vi ho lasciato i link Ora tutto questo è fighissimo no Cioè abbiamo i dati aperti risolto tut abbiamo risolto e eh c'è sempre un ma nella vita sempre e il ma è che funziona così che è garbagine e garbageout Ok Se voi non curate tanto il dato quindi il dato non è di qualità anche io dico sfruttando la conoscenza di dominio degli esperti human the loop non può essere sempre solo tutto automatico Se non è quello è chiaro che il risultato non sarà di alta qualità e gli impatti possono essere poco affidabili cioè il risultato è poco affidabile quindi non me ne faccio granché e rischio di magari spendere anche un fottio di soldi per poi non avere una soluzione efficace E infatti e qui veniamo a quello che dice Agib che ho trovato proprio qualche giorno fa che ho detto questo lo devo inserire le mie presentazioni perché è fondamentale ha pubblicato la prima visto che ci sono anche rappresentanti che viene a fagiolo insomma ha pubblicato la prima indagine sull'uso del della INE pubbliche amministrazioni centrali centrali ok non quelle locali e ha analizzato tipo 120 progetti se non ricordo male sono tantissimi eh 120 progetti sono veramente tanti in realtà più di machine learning che di intelligenza artificiale generativa dicono e mi ha colpito quella cosa che ho scritto in rosso ehm che ho evidenziato il rosso intanto il fatto che fanno allenamento loro ok Però forse ci sta perché nel machine learning sei supervisionato devi fare tu i dataset devi allenare quindi puoi usare delle tue banche inter banche dati interne quindi ci può stare Perchice si rileva scarsa attenzione alla qualità dei dati con possibili impatti negativi sull'affidabilità quindi la scarsa attenzione cioè non è tanto successo qualcosa cioè proprio è come dire non mi interessa Ok E questo è intanto tanto di cappello ad Agid che ha scritto una cosa del genere sul sito web ufficiale dellaione e poi è il vero dramma diciamo di tutta la situazione che io vedo in questo momento su questo Quindi noi abbiamo bisogno io dico e ho detto non più di open data by design non più privacy by design ma data quality by design che vuol dire tutte e due le cose insieme ok Perché detta quality è una cosa che con Antonio lo sappiamo bene insomma abbiamo scritto delle linee guida del passato dove abbiamo parlato di qualità del dato abbiamo parlato degli standard ISO del di qualità del dato il 25012 Ci sono 15 caratteristiche di qualità del dato tra cui la timeliness ok Il tempo giusto Io ho visto e questo lo dico ad Antonio ti prego togliete togliete da dati quei cavolo di dataset anche di ministeri importanti centrali aggiornati al 2021 come una frequenza d' aggiornamento annuale È veramente da mettersi i brividi Ok lì c'è qualcosa che non funziona Ok Oppure se non lo so se sistema il processo non lo so che cosa sia successo ma non può stato il Covid è Covid nel 2021 effettivamente è il Covid Però io dico una cosa qui noi dobbiamo avere per i dati i principi fair sempre generali sempre meno senza quelli non si va da nessuna parte è il minimo dobbiamo iniziare da quello è già ed è già difficile raggiungerli ok è già quello le caratteristiche di qualità dei dati che si possono comporre con i principi fail abbiamo anche fatto con dati come vorrei ehm insieme e secondo me dobbiamo agire in maniera diversa fin dalle prime fasi del processo Intanto bisogna porsi le giuste domande sui dati che a cui si vuole rispondere cose che non facciamo quasi mai e anche quello determina un po' come li raccolgo du dobbiamo raccoglierli con i principi di qualità in testa Io a volte sento ah ma sai nel form la data era obbligatoria però poi nel dato non c'è e quindi come fa a essere obbligatoria Se nel form è obbligatoria mi devi bloccare se se non ce la metto Cioè già lì tu devi controllare la qualità del dato Perché ho come l'impressione in moltissimi sistemi che adesso anche sto vedendo che si fa sempre dopo a valle cioè si si consente la monnezza iniziale di la qualunque e poi intanto dopo uno dice vabbè dopo nel processo sistemo ma quel dopo nel processo sistemo è è difficilissimo è molto più dispendioso fatelo da prima Controllate i dati da prima in termini di qualità Quindi concludendo perché è tardi e vi voglio anche lasciare andare Eh no come no Interventi è il nostro portavoce Quindi vai La prima cosa è che secondo me la pubblica amministrazione con appunto questa idea anche dell'apertura dei dati può avere un ruolo cruciale nella costruzione di quelle infrastrutture che dice Lodi non Lodi lost l apostrofo odi Ok ehm quell'infrastruttura del data as service cioè sta roba di abbandoniamo il document based no Adottiamo il data driven PA finalmente questo lo dico lo dicevamo già tra l'altro sempre con Antonio secoli fa ma ora più che mai questo deve valere ok E in particolare proprio con gli open data e vi dirò anche di più gli open data di adesso non vanno bene Mi dispiace questo messaggio netto dare open data che noi abbiamo adesso in Italia tranne forse qualche eccezione non vanno bene per fare le cose che abbiamo visto prima Bisogna alzare l'asticella perché appunto c'è scarsa attenzione alla qualità del dato Dobbiamo fare molto ma molto ma molto di più cioè dobbiamo andare oltre a dire pubblico su amministrazione trasparente uno scarica open data e li finisce Ok E un'altra cosa molto dura che vi dico è che secondo me bisogna mettersi nella testa e qui un concetto di cultura del dato che il modo con cui noi lavoriamo con i dati non è più quello anche solo di 5 anni fa Non voglio andare tanto indietro nel tempo ma anche solo di 5 anni fa non non è più quello Il mondo è completamente cambiato da un punto di vista tecnologico Ci sono delle sfide enormi che avete visto e non possiamo più gestire il dato come abbiamo sempre gestito finora Lo so che cambiare è difficile però dobbiamo considerare di rivedere completamente i processi E questa è un'altra cosa che dico l'intelligenza artificiale in Italia potrebbe fallire se noi facciamo l'errore che abbiamo fatto con altre soluzioni anche ai tempi del Covid di buttare questo elemento dentro dei processi che sono quelli che noi abbiamo da non so quanto tempo a questa parte Non saranno mai efficaci non produrranno mai dei risultati efficaci Bisogna ripensare a tutta la filiera e bisogna mettersi lì e farlo Ci vuole tempo sì Ci vuole sforzo sì Ma lo dobbiamo fare se vogliamo avere dei risultati concreti e se crediamo veramente nel valore aggiunto dei dati e dei dati aperti che sono quelli come c'è scritto qua che in un qualche modo possono essere usati per l'allenamento mettendo tutti allo stesso piano perché sono più democratici di altri dati Ok io ho concluso vi ringrazio