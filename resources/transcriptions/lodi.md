Grazie, grazie per l'invito. Dicevo prima che ho scelto di venire qua in presenza, quindi... insomma, perché avevo fatto questa cosa anche a Trieste e mi dispiace di avervi fatto cambiare anche il programma.

Eh, io oggi volevo cercare di, eh, qui, parlare di questa occasione dei dati aperti (l'ho messo tra parentesi perché, in realtà, in generale, io adesso mi occupo non solo dei dati aperti, ma di dati a 360°) e, però, secondo me, a maggior ragione, i dati aperti nell'era dell'intelligenza artificiale... e cerchiamo di capire perché, no?

E di solito, quando faccio questa presentazione, adesso dove ci si mette l'intelligenza artificiale, perché sennò non si è nessuno nella vita ormai, ci metto sempre degli esempi con ChatGPT per far capire. Ho scelto ChatGPT, avrei potuto scegliere qualunque altro modello di intelligenza artificiale generativa di ultima generazione, per farvi capire un po' il perché voglio arrivare a parare in un certo punto.

Allora, ho chiesto a ChatGPT... ho fatto due, in realtà, ho fatto due domande, no? Ho voluto cercare di capire se ChatGPT conosce qualcosa sui nostri beni culturali italiani. Gliel'ho fatto in inglese perché è meglio, insomma, no? Perché poi, lo sapete, che con le lingue anche questo è un altro problema di questi LLM. Ehm, e gli ho chiesto il numero di siti, diciamo, che sono liberamente accessibili nella regione Lazio. Una risposta piuttosto ampia e argomentata, diciamo. E vabbè, lì poi ti ritornano... e dice (ve l'ho evidenziato in rosso) che ci sono circa dai 200 ai 250 siti, eh, quindi luoghi della cultura nella regione Lazio, che offrono un accesso libero sia permanentemente oppure in certi giorni specifici della settimana, per esempio, come può essere la prima domenica del mese. Ok.

Questa risposta è interessante, nel senso che per un utente normale, ok, è una risposta molto buona, eh, però molto probabilmente... Poi gli ho fatto un'altra domanda. Gli ho detto: &quot;Quanti posti a Milano sono classificati come gallerie d'arte?&quot;. E, eh, e lui mi ha detto che, secondo i dati recenti, insomma, disponibili, Milano ha circa dai 90 ai 100 posti classificati come galleria d'arte. Ok. Quindi anche questa risposta, se vedete, è abbastanza simile, no?

E quindi, ok, però mi sono detta: &quot;Vabbè, ma noi abbiamo i Linked Open Data dei beni culturali italiani, no? E quindi, perché non chiedere al Ministero della Cultura, che li pubblica e tiene speranzosamente aggiornati, le stesse identiche domande, per vedere se il risultato è uguale?&quot;. Ehm, e quindi l'ho chiesto ad ArCo. ArCo è la rete, no? È il knowledge graph, il grafo della conoscenza aperto dei beni italiani. Fatta la prima... Naturalmente, per chiederlo al knowledge graph, devo fare delle query SPARQL. Ok. Io un po' di SPARQL lo conosco, magari non proprio tutti tutti, però ci ho provato, no? E ho fatto una mia query SPARQL e alla prima domanda mi ha risposto: 432. Mi ricordo che ChatGPT aveva detto tra i 200 e i 250, quindi in realtà sono il doppio, ok, eh, più o meno. E nella seconda domanda, eh, lui aveva risposto tra i 90 e i 100. In realtà sono 58. Mh. Eh, allora, qui c'è qualcosa che non va. Ok.

Eh, questo per dirvi che: attenzione a usare quei software in un certo modo. Vi dico anche perché. Un po' di tempo fa ChatGPT non aveva, adesso ce l'ha, la possibilità di abilitare la ricerca sul web. Non l'avevo abilitata. Ho usato l'LLM così come nasceva, ok? Quella funzionalità di andare a cercare un sito web è nata successivamente e non è una cosa intrinseca dell'LLM, è aggiuntiva, che lui usa per aiutarsi a migliorare le sue risposte. La cosa che sicuramente emerge è che queste risposte a volte sono sbagliate, semplicemente cosiddette sbagliate.

Allora, cosa abbiamo cercato di fare? Anche nelle mie tante vesti e cappelli che ho, tra socia di una spin-off del CNR, laboratorio di ricerca, ho detto: &quot;Vabbè, ma scusatemi, se io ho questi dati aperti così puntuali, precisi, aggiornati e quant'altro, perché non li uso per fare in modo che ChatGPT mi risponda in maniera puntuale?&quot;. Ok? Quindi cerco di mettere in piedi delle tecniche affinché gli LLM usino queste banche dati strutturate per poter migliorare le loro risposte. E infatti, così abbiamo fatto. Abbiamo cercato di mettere insieme ChatGPT e i dati aperti e, se guardate la risposta, adesso la risposta diventa corretta, cioè lui ti risponde &quot;432&quot;, esattamente com'è la query SPARQL. E la stessa cosa capita con l'altra: dice &quot;58&quot;, esattamente com'è il risultato della query.

Ora, che cosa ho fatto qua? In realtà, semplicemente, ho detto agli LLM, e quindi all'intelligenza artificiale generativa: &quot;Usa delle banche dati esterne per migliorare i tuoi risultati&quot;. Questo perché? Perché, eh, lo sappiamo, o se non lo sappiamo adesso dobbiamo iniziare a capirlo per bene fino in fondo, che, ehm, questi software di intelligenza artificiale producono quelle che vengono chiamate &quot;allucinazioni&quot;.

Allora, è un termine, lo dicevo anche recentemente sui social network, che non mi piace, &quot;allucinazione&quot;, però tecnicamente ormai è il termine che si usa per indicare il fatto che è uno dei grossissimi problemi: producono risposte a volte che non sono vere, ma sembrano verosimili. Cioè, una persona che non sa niente di quello che vi ho raccontato finora si fida. Il &quot;200, tra i 200 e 250&quot;... poi, tra l'altro, &quot;tra i 200 e 250&quot;, quindi c'è un range, no? E quindi è portato a fare questa cosa. Io mi ricordo, qualche... boh, forse l'anno scorso, c'era un colloquio tra due ragazzi in autobus e che dicevano... lei diceva a lui: &quot;Ma perché non l'hai chiesto a ChatGPT l'orario in cui passa l'autobus?&quot;. E io... e volevi rispondere o no? E io, a parte che volevo rispondere... ma vabbè. Ma il discorso, però... assurdo! Ma è stato, secondo me, il fatto di aver messo a disposizione, lasciatemi dire, alle masse, dei software del genere, che da un lato ha avuto dei, secondo me, degli aspetti stra-positivi, dall'altro lato ci sono degli aspetti negativi e bisogna stare attenti.

Di recente c'è stato un post, ha pubblicato un articolo che si intitolava: &quot;Perché spesso ChatGPT si inventa le cose?&quot;, no? Per parlare appunto di queste allucinazioni. E c'è un ricercatore del Politecnico di Milano, Stefano Zanero, non so se lo conoscete, molto famoso nell'ambito della cybersecurity italiana, che diceva: &quot;Guardate che loro non è che si inventano spesso le cose, lo fanno sempre&quot;. Cioè, è il loro *modus operandi*, perché loro semplicemente si basano su dei modelli matematici, dietro, statistici, e vanno a vedere qual è la probabilità che una parola sia seguita da un'altra parola. Come fanno a fare questo? Hanno un corpus su cui sono stati addestrati, dei dati in quel caso non strutturati, perché la maggior parte è testo, eh, dove deducono, attraverso tutta una serie di, eh, pesi che attribuiscono alle varie parole all'interno di un certo discorso. Ed è impressionante, a volte, seriamente impressionante. Così come è impressionante il fatto che, nelle domande di prima, se abilitate la ricerca sul web, lui andava a cercare nel sito giusto, ok? Non un sito a caso, ma proprio nel sito giusto per andare a trovare la risposta. Quindi ci sono delle cose abbastanza *impressive*, ok?

Però bisogna stare attenti, perché appunto, questo fenomeno è lì, c'è, dobbiamo tenerlo in considerazione. Dobbiamo essere consapevoli, quando usiamo questi software, che questo fenomeno c'è e dobbiamo lavorare per mitigare.

L'altro punto fondamentale, secondo me, di questi software è che sono delle &quot;scatole nere&quot;, no? Nel senso che, in realtà, nessuno ancora è in grado di spiegare che cosa avviene là dentro. Nel senso che, eh, vi dicevo prima, ci sono dei modelli statistici alla base di questi software, ok? È tutto basato su pesi, eh, che vengono attribuiti. Se questi pesi, tra l'altro, non sono aperti, quindi non sono open source, per esempio, è difficile riuscire a capire come lui si costruisce il suo modello. Perché fa questo? In realtà, in base al dato di input: quindi tanto il dato di input cambia, tanto anche il modello dentro si può adattare e crea questo modello per produrre un risultato. Ma noi non lo sappiamo qual è, effettivamente, eh, come ci arriva a produrre quel risultato. E infatti, spesso si dice che non si riesce a spiegare il perché mi ritorna quel risultato lì. Pensate: se non so nemmeno qual è il dato di input, come posso arrivare a capire qual è il suo risultato finale? No?

E altra caratteristica, e questo è il grande tema di cui si accennava poco fa, è che ignorano completamente (questo è un po' l'uso anche che ne viene fatto da coloro che hanno sviluppato questi software) qualunque tipo di vincolo che può esistere sul dato, che sia esso strutturato o non strutturato. Io dico sempre che fanno un po' &quot;di cojo cojo&quot;, nel senso che fanno scraping sul web di qualunque pagina, ok? E attenzione, usano molto (e qua c'è uno studio a livello UK) i siti web delle pubbliche amministrazioni, fanno scraping di quelle informazioni. Quindi ragionate anche su questo: se il vostro sito web della Pubblica Amministrazione non è aggiornato, pensate che cosa può venire fuori, visto che già non producono risposte veritiere per definizione. Ok? E, eh, ignorano tutto questo tema. Ed è un tema enorme, seriamente enorme, che secondo me ancora non è stato affrontato. Tra l'altro, il risultato che loro producono, di chi è la proprietà intellettuale? Chi l'ha prodotto? La macchina stessa o sono tutti gli input che lui mette insieme che producono questa cosa? Cioè, ci sono dei ragionamenti lì fuori, nell'uso di questi software, che noi dovremmo iniziare a fare e che, secondo me (adesso vi arrivo a sperare, spero di convincervi), gli Open Data possono essere un buon veicolo per cercare di tamponare questa situazione.

Infine, non esistono se non ci sono dati, ok? Cioè, non esiste intelligenza artificiale se non ci sono dati, non avrebbe nessun tipo di senso. E il risultato dipende fortemente dal dato di input, per come vi dicevo prima, per come sono tecnicamente fatti. Quindi che cosa vuol dire questo? Che se quel dato non è completo, per esempio, il risultato non potrà mai essere completo. Mi ricordo che c'era un esempio, e spesso lo ricordo, dell'uso dell'intelligenza artificiale nell'ambito della giustizia americana, che poi è stato completamente vietato a un certo punto perché era eclatante. I dati di input erano, la maggior parte delle volte, sentenze contro persone di colore e quindi il risultato era sempre che si andava a imputare una persona di colore, magari quando forse il reato era stato commesso, in quel caso, da una persona invece, eh, bianca, diciamo così. Ecco, questo per dirvi che attenzione, perché se poi li usiamo per prendere delle decisioni che hanno un impatto sulla nostra vita, diventa abbastanza, eh, problematico.

E allora io dico, e qui riporto una cosa che dice, in realtà, non io, eh, perché ormai è già stato detto tutto dall'Open Data Institute: secondo me bisogna ripartire da questi principi. Questo è stato pubblicato proprio non molto tempo fa da loro, come una sorta di manifesto d'intenti, diciamo così. E ci sono due principi che mi hanno colpito nello specifico. Il primo dice che ci vuole, nell'era dell'intelligenza artificiale, una *strong data infrastructure*, ok? Perché dobbiamo costruire un qualcosa che sia, eh, un ecosistema di dati di fiducia, in un qualche modo. E per costruirla, dobbiamo tenere in considerazione tutto lo spettro dei dati, ok? Tra l'altro, questa figura che vedete qua è vecchissima. Io, tra l'altro, insegno anche all'università ai miei studenti. È una figura, secondo me, che veramente vi dice un po' tutto lo spettro dei dati, guardando anche diverse dimensioni: se sono piccoli, medi, grandi; se sono personali, commerciali o del governo (del settore pubblico); se sono chiusi, se sono condivisi e se sono completamente aperti, no?

Quindi, per gestire tutto questo, ok, noi abbiamo bisogno di, eh, nell'era dell'intelligenza artificiale, avere delle pratiche che mi consentono di gestire in maniera forte. E dicono anche che la miglior possibile *foundation*, quindi il pilastro di tutto questo, è il dato aperto. E io perché dico di ripartire da qua e da questa cosa? Perché riprendiamo i problemi e i limiti che abbiamo visto prima, no? E come i dati aperti ci possono aiutare?

Allora, le allucinazioni: vi ho portato un esempio pratico dove le allucinazioni erano lì, però ho usato i dati aperti e ho migliorato i risultati. Quindi, eh, in questo caso, da un punto di vista tecnico, ho usato una tecnica che si chiama RAG, che sta per *Retrieval-Augmented Generation*. Sostanzialmente, gli do una base di conoscenza, ok? Posso farlo anche con una banca dati che è completamente chiusa, eh, non è necessariamente con dati aperti. Però, eh, ho usato questa tecnica per cercare di mitigare e ridurre l'effetto delle allucinazioni. E i dati aperti sono uno strumento, secondo me, micidiale da questo punto di vista, perché chiunque li può guardare, i dati aperti, quindi chiunque può anche riconoscere la qualità di quei dati, ok? Nel momento in cui noi ci apriamo e ci offriamo all'intelligenza collettiva, ci apriamo anche alla possibilità di poter migliorare questi dati, e questo non può che essere uno strumento fondamentale per cercare di mitigare un fenomeno come quello dell'allucinazione.

Eh, abbiamo detto che sono delle &quot;scatole nere&quot;, no? Quindi, mi raccomando, una cosa importante: non fanno ragionamenti, non hanno un'idea di concetto, di contesto di questo tipo. Io a volte sento: &quot;Ah, ma arrivano ad avere emozioni!&quot;. No. No, assolutamente no. È tutta roba iper-mega-statistica, ok? Con modelli matematici molto spinti dietro, ma non hanno queste capacità, ok? Perché qui dico che, eh, i dati aperti, nel caso delle &quot;scatole nere&quot;, potrebbero aiutare? Intanto, perché se, ehm, io potrei, per esempio, se uso dei dati aperti in input, spiegare perché arrivo a un certo risultato. Qualche anno fa (perché nel mondo della ricerca siamo sempre un pochino più avanti, ammettiamolo) c'è stata una bellissima presentazione a un forum, insomma, della comunità del Semantic Web (tra parentesi), che faceva vedere come, dato un knowledge graph, ehm, tra l'altro con delle immagini, ok, questi software potevano essere migliorati e si poteva spiegare come loro arrivavano a un certo risultato e come potevano arrivare al risultato corretto, usando appunto strumenti di dati strutturati in un certo modo, con una certa semantica e che spiegano anche il significato dei dati.

Quindi, l'explainability di questi software, che è un altro tema di ricerca molto ampio, potrebbe essere assolutamente indirizzata con la disponibilità di dati aperti riutilizzabili da chiunque. Perché i dati aperti possono essere anche proprio utilizzati per l'allenamento di questi software, anche per il famoso principio di trasparenza che ci impone l'AI Act (che sapete, no?, che è questa norma europea) che dice che i software di intelligenza artificiale devono essere classificati in base a un certo rischio e, se sono ad alto rischio perché hanno un impatto e un risultato sugli esseri umani, devono rispettare condizioni di trasparenza. Quindi, per esempio, dovreste dire quali sono i dataset su cui voi allenate il software, ok? Allora, se sono dati aperti, tanto più è agevolato questo compito.

Eh, ignorano i vincoli sui dati. Ma noi abbiamo i dati aperti! I dati aperti non hanno vincoli, o se li hanno, ce li hanno pochi, no? E quindi forse riusciamo anche a mettere a posto un pochino questo aspetto legale enorme che loro hanno, no? Quindi, perché no? Perché non sfruttare questo fatto di usare i dati aperti in questo senso? Poi mi rendo conto che non è che tutti i dati sono esclusivamente dati aperti, perché bisogna bilanciare: ci sono anche dati personali che devono essere trattati in un certo modo. Però c'è una grande fetta di dati che può essere dato aperto e può essere utilizzata.

Infine, abbiamo detto che senza dati non esistono. I dati aperti sono per definizione dei dati che dovrebbero, dovrebbero, dovrebbero avere un formato aperto e quindi *machine-readable*. Dovrebbero. Ok? E quindi, a maggior ragione, vuol dire accessibili, disponibili, no? E quindi ci aiutano tantissimo per poter, eh, usare questi software. Lasciatemi dire anche, visto che ho una piccola società, una spin-off del CNR: se ci fossero più dati aperti di qualità non sarebbe male anche per noi, perché sarebbe un vantaggio anche di competizione. Perché una società in miniatura come la nostra come fa a competere con OpenAI, Microsoft, che c'ha tutto il mondo, o Google? Ok? È chiaro che non riesce a competere. Se invece abbiamo i dati aperti, che mettono tutti, nel riutilizzo, allo stesso piano, è chiaro che pure io posso fare qualcosa.

Quindi, ritornando sempre all'Open Data Institute, i dati aperti potrebbero diventare veramente l'infrastruttura ideale per l'allenamento di questi software di intelligenza artificiale. E loro, guardate che cosa dicono qua (tra parentesi): dicono che un dato che è pronto per l'addestramento all'intelligenza artificiale significa, in pratica, eh, applicare diverse pratiche, tra cui i principi FAIR, ok? *Findable, Accessible, Interoperable, Reusable*. E non solo per i dati della ricerca, ma per tutti i dati. Ok? Linked Data, ok? E qui, vabbè, torna un po' la mia battaglia nazionale, insomma, diciamo così. Perché? Perché i Linked Data sono dati collegati ad altri dati per definizione, con una semantica, e quindi possono avere tutti quei vantaggi che vi dicevo precedentemente. E dicono anche che nel creare dati aperti bisogna avere in mente queste potenzialità dei software di intelligenza artificiale. Cioè, dicono: &quot;Guardate che il governo dovrebbe garantire di pubblicare dei dati di alta qualità, secondo tutte quelle buone pratiche, proprio per evitare che magari questi software vadano a cercare dati in sorgenti secondarie, magari non autoritative come nel caso del governo, proprio per dare un risultato migliore&quot;. E soprattutto quando si parla di intelligenza artificiale applicata, per esempio, ai servizi pubblici, ok? Senza affidarsi a Tizio che scrive nel suo blog che quel servizio pubblico è fatto in questo modo. Ok?

Eh, vi ho lasciato i link. Ora, tutto questo è fighissimo, no? Cioè, abbiamo i dati aperti, risolto tutto, abbiamo risolto. E, eh, c'è sempre un &quot;ma&quot; nella vita, sempre. E il &quot;ma&quot; è che funziona così: *garbage in, garbage out*. Ok? Se voi non curate tanto il dato, quindi il dato non è di qualità (anche, io dico, sfruttando la conoscenza di dominio degli esperti, *human-in-the-loop*, non può essere sempre e solo tutto automatico), se non è quello, è chiaro che il risultato non sarà di alta qualità. E gli impatti possono essere poco affidabili, cioè il risultato è poco affidabile, quindi non me ne faccio granché e rischio di magari spendere anche un fottio di soldi per poi non avere una soluzione efficace.

E infatti, e qui veniamo a quello che dice AgID, che ho trovato proprio qualche giorno fa e ho detto: &quot;Questo lo devo inserire nelle mie presentazioni perché è fondamentale&quot;. Ha pubblicato la prima (visto che ci sono anche rappresentanti, viene a fagiolo, insomma) indagine sull'uso dell'IA nelle Pubbliche Amministrazioni centrali. Centrali, ok? Non quelle locali. E ha analizzato tipo 120 progetti, se non ricordo male. Sono tantissimi, eh, 120 progetti sono veramente tanti. In realtà, più di machine learning che di intelligenza artificiale generativa, dicono. E mi ha colpito quella cosa che ho scritto in rosso, ehm, che ho evidenziato in rosso. Intanto, il fatto che fanno allenamento &quot;loro&quot;, ok? Però forse ci sta, perché nel machine learning, se è supervisionato, devi fare tu i dataset, devi allenare, quindi puoi usare delle tue banche dati interne, quindi ci può stare. Però dice: &quot;Si rileva scarsa attenzione alla qualità dei dati, con possibili impatti negativi sull'affidabilità&quot;. Quindi la scarsa attenzione... cioè, non è tanto &quot;è successo qualcosa&quot;, cioè, proprio è come dire: &quot;Non mi interessa&quot;. Ok. E questo, intanto, tanto di cappello ad AgID che ha scritto una cosa del genere sul sito web ufficiale dell'istituzione. E poi è il vero dramma, diciamo, di tutta la situazione che io vedo in questo momento su questo.

Quindi noi abbiamo bisogno, io dico e ho detto, non più di *open data by design*, non più *privacy by design*, ma *data quality by design*, che vuol dire tutte e due le cose insieme, ok? Perché la *data quality* è una cosa che con Antonio lo sappiamo bene, insomma, abbiamo scritto delle linee guida in passato dove abbiamo parlato di qualità del dato, abbiamo parlato degli standard ISO di qualità del dato, il 25012. Ci sono 15 caratteristiche di qualità del dato, tra cui la *timeliness*, ok? Il tempo giusto. Io ho visto, e questo lo dico ad Antonio: &quot;Ti prego, togliete, togliete da dati.gov.it quei cavolo di dataset, anche di ministeri importanti, centrali, aggiornati al 2021 con una frequenza di aggiornamento annuale!&quot;. È veramente da mettersi i brividi. Ok? Lì c'è qualcosa che non funziona. Ok. Oppure, non lo so, se si sistema il processo... non lo so che cosa sia successo, ma non può... è stato il Covid? È il Covid nel 2021, effettivamente è il Covid. Però io dico una cosa: qui noi dobbiamo avere per i dati i principi FAIR. Sempre. Generali, sempre. Almeno. Senza quelli non si va da nessuna parte, è il minimo. Dobbiamo iniziare da quello, ed è già difficile raggiungerli, ok? È già quello.

Le caratteristiche di qualità dei dati, che si possono comporre con i principi FAIR... l'abbiamo anche fatto con &quot;Dati, come vorrei&quot;, ehm, insieme. E secondo me dobbiamo agire in maniera diversa fin dalle prime fasi del processo. Intanto, bisogna porsi le giuste domande sui dati a cui si vuole rispondere, cose che non facciamo quasi mai, e anche quello determina un po' come li raccolgo. Due: dobbiamo raccoglierli con i principi di qualità in testa. Io a volte sento: &quot;Ah, ma sai, nel form la data era obbligatoria, però poi nel dato non c'è&quot;. E quindi come fa a essere obbligatoria? Se nel form è obbligatoria, mi devi bloccare se non ce la metto. Cioè, già lì tu devi controllare la qualità del dato. Perché ho come l'impressione, in moltissimi sistemi che adesso anche sto vedendo, che si fa sempre dopo, a valle. Cioè, si consente la &quot;monnezza&quot; iniziale, di qualunque tipo, e poi intanto dopo uno dice: &quot;Vabbè, dopo nel processo sistemo&quot;. Ma quel &quot;dopo nel processo sistemo&quot; è difficilissimo, è molto più dispendioso. Fatelo da prima! Controllate i dati da prima in termini di qualità.

Quindi, concludendo, perché è tardi e vi voglio anche lasciare andare... (Eh no, come no? Interventi... è il nostro portavoce, quindi vai!). La prima cosa è che, secondo me, la Pubblica Amministrazione, con appunto questa idea anche dell'apertura dei dati, può avere un ruolo cruciale nella costruzione di quelle infrastrutture che dice l'ODI, non Lodi, l'apostrofo ODI (Open Data Institute), ok? Quell'infrastruttura del *data-as-a-service*, cioè 'sta roba di: &quot;Abbandoniamo il *document-based*, no? Adottiamo la PA *data-driven*!&quot;. Finalmente. Questo lo dico... lo dicevamo già, tra l'altro sempre con Antonio, secoli fa, ma ora più che mai questo deve valere, ok?

E in particolare, proprio con gli open data. E vi dirò anche di più: gli open data di adesso non vanno bene. Mi dispiace, questo è un messaggio netto da dare. Gli open data che noi abbiamo adesso in Italia, tranne forse qualche eccezione, non vanno bene per fare le cose che abbiamo visto prima. Bisogna alzare l'asticella, perché, appunto, c'è scarsa attenzione alla qualità del dato. Dobbiamo fare molto, ma molto, ma molto di più. Cioè, dobbiamo andare oltre il dire: &quot;Pubblico su Amministrazione Trasparente, uno scarica l'open data e lì finisce&quot;. Ok?

E un'altra cosa molto dura che vi dico è che, secondo me, bisogna mettersi nella testa (e qui è un concetto di cultura del dato) che il modo con cui noi lavoriamo con i dati non è più quello anche solo di 5 anni fa. Non voglio andare tanto indietro nel tempo, ma anche solo di 5 anni fa: non è più quello. Il mondo è completamente cambiato da un punto di vista tecnologico, ci sono delle sfide enormi che avete visto e non possiamo più gestire il dato come abbiamo sempre gestito finora. Lo so che cambiare è difficile, però dobbiamo considerare di rivedere completamente i processi. E questa è un'altra cosa che dico: l'intelligenza artificiale in Italia potrebbe fallire se noi facciamo l'errore che abbiamo fatto con altre soluzioni, anche ai tempi del Covid, di buttare questo elemento dentro dei processi che sono quelli che noi abbiamo da non so quanto tempo a questa parte. Non saranno mai efficaci, non produrranno mai dei risultati efficaci. Bisogna ripensare a tutta la filiera e bisogna mettersi lì e farlo. Ci vuole tempo? Sì. Ci vuole sforzo? Sì. Ma lo dobbiamo fare, se vogliamo avere dei risultati concreti e se crediamo veramente nel valore aggiunto dei dati e dei dati aperti, che sono quelli, come c'è scritto qua, che in un qualche modo possono essere usati per l'allenamento, mettendo tutti allo stesso piano perché sono più democratici di altri dati. Ok.

Io ho concluso, vi ringrazio.