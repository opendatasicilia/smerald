Eccoci. Allora, buon pomeriggio a tutti e grazie a Davide, CNR, Open Data Sicilia per l'invito. È la prima volta, mi sa, che vengo a un evento di Open Data Sicilia e mi fa molto piacere, chiaramente, perché ci conosciamo da tanto tempo e condividiamo diverse cose, insomma.

A me tocca il compito di fare una panoramica sulle policy, quindi sicuramente le cose più accattivanti arriveranno dopo, però diciamo che può essere utile fare anche insieme questo quadro, perché poi, come sappiamo, l'interoperabilità è basata su regole e quindi conoscere le regole che ci aiutano a garantire interoperabilità, Open Data, intelligenza artificiale, eccetera, può essere utile a tutti.

Allora, io, vabbè, lavoro in AgID, nell'area che si chiama 'Interoperabilità, Dati e Accessibilità'. Come sapete, AgID, tra le altre cose, fa anche linee guida su diversi aspetti (poi lo vedremo), per cui fa le regole che poi sono alla base di tutte le attività delle pubbliche amministrazioni, che devono mettere a disposizione i dati, devono realizzare servizi e API e devono implementare, ormai, anche l'intelligenza artificiale.

Quindi, allora, lo sappiamo, sicuramente non ve lo devo dire, ma da quando stiamo parlando in maniera più importante, diciamo, ormai da qualche anno, di intelligenza artificiale, automaticamente parliamo di dati e di qualità dei dati. Nel senso, è come se con l'intelligenza artificiale avessimo scoperto l'importanza dei dati, l'importanza di avere dati di qualità, perché comunque ci siamo scontrati direttamente. Lo sapevamo già prima, ma è probabilmente più lampante in questo ultimo periodo: abbiamo visto che se non ci sono dati di qualità, alla fine le risposte che l'intelligenza artificiale ci dà sono quantomeno inesatte, diciamo. E quindi abbiamo scoperto che effettivamente quello che dicevamo da anni, quindi se io ho dati in ingresso che non sono puliti, non sono di qualità, è chiaro che qualsiasi cosa faccia (servizi digitali, applicazioni, eccetera) chiaramente non sarà efficace ed efficiente.

Ed effettivamente, questa grande ondata di attività sull'intelligenza artificiale avrà successo, e lo dice anche il Parlamento Europeo direttamente, solo se le strategie sui dati, e quindi tutte le attività sui dati, avranno successo. Cioè, se continueremo a pubblicare dati che non sono di qualità, è chiaro che anche l'intelligenza artificiale è destinata a non produrre i risultati che ci auspichiamo. Ed effettivamente l'AI Act lo dice chiaramente. Lo dice chiaramente: il regolamento sull'intelligenza artificiale si rivolge soprattutto a sistemi ad alto rischio, però il discorso è valido per tutti i sistemi di intelligenza artificiale, e cioè che servono adeguate pratiche di governance e gestione dei dati perché ci sia a disposizione una grande disponibilità di dati e dati di qualità. Ora, quello che dico io non è che in altri casi, senza intelligenza artificiale, non debbano essere garantite queste condizioni, perché se noi facciamo un servizio pubblico digitale ci servono grandi quantità di dati e ci servono dati di qualità, così per qualsiasi altra cosa. Quindi sono cose scontate che stanno prendendo di nuovo e forse l'intelligenza artificiale ci può aiutare a recuperare molto tempo che abbiamo forse perso negli anni passati, per arrivare, si spera, a queste grazie a queste condizioni.

Chiaramente, da diversi anni, prima del regolamento sull'intelligenza artificiale, quindi prima che nascesse tutta questa discussione e queste attività degli ultimi anni, in realtà l'Europa, la Commissione Europea e, di conseguenza, anche i vari Stati membri, stanno lavorando da diversi anni sulle strategie per i dati. C'è la grossa fetta degli Open Data. Sapete, nel 2019 c'è stata la nuova direttiva – lo vedremo meglio dopo – che, lo dicevamo con Andrea recentemente, finalmente si chiama 'direttiva sull'apertura dei dati'. Prima era 'Public Sector Information', che era una cosa molto più generica, ma non rendeva subito l'idea, ecco. Però, l'approccio che la Commissione Europea sta adottando è che si deve aumentare l'offerta dei dati, non solo dati aperti: anche tutti gli altri dati che non possono essere aperti per diversi motivi devono comunque circolare, in modo tale che quei dati possano creare valore così come lo possono fare gli Open Data.

E quindi è intervenuto il Data Governance Act, che praticamente è complementare alla disciplina Open Data e quindi riguarda quei dati che non possono essere pubblicati come dati aperti perché, per esempio, ci sono questioni di protezione dei dati personali, ci sono questioni di segreto commerciale, quindi c'è un impatto sulle attività commerciali, oppure c'è la proprietà intellettuale. Nonostante questa limitazione, il Data Governance Act dice che gli enti pubblici devono rendere comunque disponibili questi dati. Chiaramente, non saranno disponibili a tutti e per tutti gli scopi come gli Open Data, ma si innesca un processo di, diciamo, scambio sicuro e affidabile e con attori che si conoscono, perché chiaramente c'è chi fornisce il dato e c'è chi lo deve riutilizzare, per cui l'amministrazione, in questo caso, sa effettivamente chi lo riutilizza e, se lo può riutilizzare, lo fa riutilizzare.

Collegato al meccanismo, diciamo, e all'attività di trattamento in ambiente sicuro, o meglio, il Data Governance Act fornisce anche l'inquadramento normativo per una serie di spazi di dati che si stanno costruendo a livello europeo. Comincia a esserci qualche esperienza anche in Italia. Spazi di dati che sono dei veri e propri ecosistemi che mettono insieme soggetti non solo pubblici ma anche privati (perché in agricoltura c'è l'amministrazione pubblica che produce i dati, ma ci può essere anche il singolo contadino che produce il dato) e quindi si devono mettere, diciamo, in relazione in modo tale che, nell'ambito di questo spazio di dati, questi dati, appunto, possano circolare e possano essere scambiati, anche qui, in modo sicuro, affidabile e in modo che seguano standard e regole prestabilite.

E poi, in ultimo, entrerà in vigore a settembre 2025 il Data Act. Il Data Act riguarda tutti quei dati che vengono generati attraverso dispositivi connessi a Internet, quindi dispositivi IoT. Per cui, fino ad oggi, o fino a quando non andrà in vigore il Data Act, praticamente, tutti i dati che sono prodotti da questi dispositivi solo il produttore li utilizza e decide come utilizzarli, chi li può utilizzare, eccetera. Dall'entrata in vigore si introduce un principio che si chiama proprio 'portabilità dei dati', nel senso che, una volta che viene dismesso quel dispositivo, è l'utente a decidere che fine dovranno fare quei dati, chi li può utilizzare, quindi chi può creare valore da quei dati. Per l'amministrazione pubblica – visto che a noi come AgID interessa anche, ovviamente, l'amministrazione pubblica – in questo regolamento c'è un meccanismo che fa sì che la pubblica amministrazione possa obbligare i privati a fornire questi dati nei casi di emergenza, per esempio terremoto, alluvione e quant'altro. È chiaro che all'amministrazione pubblica è utilissimo sapere subito, nel più breve tempo possibile, quali sono, per esempio, la localizzazione dei vari cittadini, dove sono dislocati, e quant'altro. In quel caso, l'amministrazione pubblica... e quindi si ha un processo, se vogliamo, perché fino ad oggi c'è stata una richiesta di dati dall'amministrazione pubblica verso il privato. È chiaro che in questo caso si inverte il flusso, quindi è il privato che contribuisce con l'amministrazione pubblica a rendere disponibili questi dati.

Questo è il quadro che si sta delineando. Poi vedremo che si sta ragionando già a un'evoluzione a livello europeo rispetto a questa strategia. Chiaramente, c'è la corrispondenza di questo framework europeo a livello nazionale, per cui, vabbè, la direttiva Open Data, chiaramente, è stata recepita; adesso vediamo un po' più nel dettaglio la guida prevista. Il Data Governance Act, chiaramente, non va recepito perché non è una direttiva, è un regolamento, quindi è direttamente applicabile, però richiedeva che fosse identificata un'autorità nazionale (che potesse essere anche più di un'autorità nazionale) che potesse presidiare tutti questi aspetti del Data Governance Act: quindi la condivisione dei dati protetti, i servizi di intermediazione dei dati, l'altruismo dei dati, e poi ne parleremo.

E questo, non voglio adesso fare il giurista – lo dicevo pure l'altra volta – però forse un po' ci tocca. Questo è il quadro, diciamo, regolatorio per quanto riguarda gli Open Data. Continua a essere valido in Italia un decreto legislativo che è del 2006, ma è stato aggiornato a seguito della direttiva del 2019. E questo decreto prevedeva che AgID adottasse delle linee guida sugli Open Data, che quindi sono dei documenti vincolanti per l'amministrazione pubblica, ma non solo, perché la direttiva Open Data ha ampliato, diciamo, l'obbligo per l'apertura dei dati non solo alle pubbliche amministrazioni, ma anche a imprese pubbliche e private che esercitano un servizio pubblico. Per cui, se abbiamo l'azienda di mobilità, che è comunque una società privata, è comunque obbligata a rendere disponibili i dati come dati aperti.

Prevedeva, dicevo, delle linee guida (ne parleremo dopo). In realtà, poi, da diversi anni – parliamo del 2007, quindi tanti anni fa – su una particolare tipologia di dati, che sono i dati geografici (su cui poi ci sarà un focus nella presentazione successiva), era stato già definito, ed è stato definito fino ad oggi, un framework di interoperabilità molto chiaro e completo. Nel senso, non esistono altre tipologie di dati che abbiano un framework di interoperabilità di dominio così dettagliato e così specifico. Tant'è vero che questo – e mi riferisco alla direttiva cosiddetta Inspire, che è la direttiva che regola, diciamo, le infrastrutture di dati territoriali – questo framework viene preso anche come esempio in altri domini, perché praticamente questo framework regola tutti gli aspetti che riguardano i dati, in questo caso i dati territoriali: dai metadati (quindi definisce un profilo di metadati), definisce per ciascuna categoria di dati delle specifiche tecniche (quindi ci sono delle regole condivise a livello europeo su tutti i temi che sono identificati in Inspire) e definisce i servizi di rete, quali devono essere e come devono essere sviluppati. Ovviamente è tutto basato su standard internazionali, sia ISO che OGC, e definisce anche le regole di scambio dei dati.

Ora, la direttiva Open Data... e qui si è creato praticamente il legame, perché fino a qualche anno fa i due mondi viaggiavano separati, diciamo. Quindi c'era il mondo Open Data da una parte e il mondo dei dati territoriali dall'altro. Tant'è vero che nella direttiva Inspire non si parla di apertura di dati, si parla solo di scambio di dati tra pubbliche amministrazioni, per cui c'era una certa, diciamo, difformità anche sul riutilizzo dei dati in questi due ambiti. Con il regolamento sui cosiddetti dati di elevato valore si crea un ponte, diciamo, tra le due discipline. Quindi, la direttiva Open Data individua, anche tra le altre cose, una serie di tipologie di dati che sono importanti per l'utilizzo, perché creano valore non solo economico, ma anche sociale e ambientale. Per esempio, esplicitamente la direttiva cita i dati dinamici, dà delle indicazioni sui dati dinamici, dà delle indicazioni sui dati di ricerca (visto che qua siamo al CNR, è uno degli ambiti che la direttiva Open Data ritiene importante ed essenziale) e poi definisce, crea diciamo, una nuova categorizzazione di dati che sono i 'dati di elevato valore', proprio perché, sulla base di studi che la stessa Commissione ha effettuato negli anni scorsi, questi dati, se riutilizzati – ed è questa la definizione esplicita data dalla direttiva – possono creare anche esplicitamente posti di lavoro e quindi avere un beneficio economico, ma anche sociale e ambientale.

Per queste sei categorie, poi, la direttiva demandava a un regolamento l'identificazione puntuale di serie di dati per ciascuna di queste categorie, cosa che è avvenuta con il Regolamento 2023/138. Se andate a vedere, o se conoscete già il regolamento, per ognuna delle sei categorie che la direttiva Open Data individua, vengono puntualmente indicate quali sono le serie di dati da rendere disponibili, secondo alcuni requisiti: quindi dati aperti, attraverso API, attraverso download in blocco, attraverso alcune regole di interoperabilità. E molti di questi dati sono, appunto, dati territoriali. E il regolamento stesso non è che va a inventarsi nuove regole: dice esplicitamente, visto che abbiamo già delle regole codificate da diversi anni su questi tipi di dati, chiaramente richiama quelle regole e dice esplicitamente che si applicano le regole su dati, servizi e metadati della direttiva Inspire per quei dati territoriali che ricadono nelle serie di dati.

A livello nazionale, sia nelle linee guida sia nel Piano Triennale (il documento che, diciamo, definisce obiettivi e risultati attesi per tutte le pubbliche amministrazioni per tutti i temi che riguardano la trasformazione digitale) e quindi, dicevo, sia nelle linee guida sia nel Piano Triennale era previsto che, per quanto riguarda i dati di elevato valore, si adottasse una guida operativa. Quindi non è a livello di linea guida vincolante, ma una guida operativa che è stata pensata, da una parte, per fare lo stato dell'arte, cioè: viste le serie di dati definite dal regolamento, a che punto siamo? Perché, chiaramente, derivando alcuni dati dalla direttiva Inspire, c'era e c'è la possibilità che alcuni dati siano già disponibili secondo la direttiva Inspire. E, come dicono molte volte le amministrazioni, se avessimo lavorato negli anni scorsi, quindi dal 2007 ad oggi, facendo in modo che tutti i dati che ricadono nell'ambito di Inspire fossero già allineati a quelle indicazioni (quindi i metadati, e sui metadati diciamo siamo abbastanza allineati, ma anche a livello di conformità dei dati o a livello di conformità dei servizi), a quest'ora il regolamento sarebbe, fatemi passare il termine, una passeggiata. Perché io ho già le API (essendo i servizi di INSPIRE considerati API), ho già i dati allineati alle specifiche tecniche e quindi già rispettano e comprendono gli attributi richiesti dal regolamento e, chiaramente, li ho già metadatati.

Chiaramente, come per tutte le applicazioni di norme, c'è una situazione abbastanza eterogenea, per cui non tutte le diverse amministrazioni l'hanno fatto e quindi adesso ci ritroviamo a inseguire, se volete, il discorso del regolamento. Il rapporto tra il regolamento sui dati di elevato valore e Inspire è lo stesso che c'è tra intelligenza artificiale e dati, nel senso che alla fine il regolamento ha rivitalizzato Inspire. Nel senso che ha ripreso le regole Inspire, ha detto 'applicate le regole Inspire', ma se lo avessimo fatto prima è chiaro che saremmo già avvantaggiati. Stessa cosa l'intelligenza artificiale: ma se avessimo già prodotto nella pubblica amministrazione dati di qualità, è chiaro che avremmo una quantità di dati utilizzabile, diciamo, molto maggiore di quanto effettivamente abbiamo.

A livello nazionale, poi, nel Codice dell'Amministrazione Digitale, relativamente a Inspire, c'è la definizione di un framework di interoperabilità su cui, ripeto, parlerà poi in un'altra presentazione. E possiamo andare... Ah, in basso. Anzi, è un test, scusate ma... facilità. Grazie.

Quindi, chiaramente, ero partito dal discorso intelligenza artificiale e dati. Noi stiamo lavorando in questo periodo sulle linee guida per l'adozione dell'intelligenza artificiale nelle pubbliche amministrazioni. C'è stata la consultazione pubblica, sono arrivati tantissimi commenti, circa un migliaio, e quindi li stiamo elaborando per poter avere un testo da far proseguire nell'iter, che prevede l'articolo 72 del CAD. Dicevamo all'inizio: il successo dell'IA si avrà solo se le strategie sui dati hanno successo. E quindi, siccome nelle linee guida sull'intelligenza artificiale c'è una sezione dedicata, ovviamente, alla gestione dei dati, lì diciamo chiaramente che le amministrazioni pubbliche sono chiamate ad attuare, se non lo avessero già fatto, tutte le policy che sono state definite in questi anni, anche a livello di linee guida sui dati.

AgID in questi anni ne ha prodotte diverse, per cui si va dall'interoperabilità tecnica, le API su cui si basa poi la PDND (e anche qui c'è una linea guida sulla PDND). Per cui, al momento, sulla PDND – l'altro giorno, diciamo, c'erano stati 640 milioni di scambi di dati fra pubbliche amministrazioni – è chiaro che questo è possibile perché ci sono regole condivise, perché le amministrazioni seguono le regole di interoperabilità tecnica, quindi espongono API che sono basate su regole condivise, e quindi, chiaramente, funziona lo scambio di dati. Ma poi ci sono, lo citavo prima, le linee guida Open Data e quindi il documento dà l'indicazione per tutto il processo di produzione e pubblicazione degli Open Data, per cui si va dall'analisi del patrimonio interno dell'amministrazione, della selezione dei dati da aprire, alla bonifica, alla valutazione, all'analisi della qualità, alla scelta dello strumento per la pubblicazione e quant'altro. E poi c'è la guida operativa sia sui dati di elevato valore che citavo prima, oltre ad alcune regole tecniche specifiche, anche qui sui dati territoriali che, comunque, in nella maggior parte dei casi sono allineati a Inspire.

Questo per dire, come dicevo prima, è chiaro che se seguiamo, diciamo, le regole che insieme decidiamo (perché tutte queste linee guida vengono fatte con un iter che è abbastanza partecipato dalle amministrazioni, perché vengono coinvolte, è partecipato anche da tutti, diciamo, gli utenti esterni, chiamiamoli esterni, perché comunque c'è un periodo di consultazione pubblica) e quindi queste sono il frutto di tutto questo processo partecipativo. E quindi le linee guida Open Data hanno definito, dicevo, una serie di requisiti e raccomandazioni per l'apertura dei dati. Tra le altre cose, siccome dicevamo prima che l'AI Act dice che bisogna mettere in campo adeguate pratiche di gestione dei dati per avere disponibilità di dati e dati di qualità, chiaramente, quando parliamo di qualità dobbiamo intenderci su cosa è la qualità. Per questo, nelle linee guida Open Data, già vengono identificate alcune caratteristiche di qualità che, in realtà, sono state riprese da documenti che sono stati pubblicati dal 2013, se non ricordo male. Quindi sono più di 10, 11 anni, insomma 12 anni che stiamo dicendo: per la qualità, considerate queste caratteristiche. Ovviamente, sono sempre basate su standard ISO.

E qual è la difficoltà? Uno, che in molti casi, e su questo si sta lavorando, chiaramente, le amministrazioni hanno bisogno di strumenti per la misura della qualità. Cioè, io dico la coerenza semantica: è chiaro che io devo avere un'ontologia, uno schema, un modello dati di riferimento per misurare se effettivamente quel dato è coerente. Ora si sta lavorando, e forse lo conoscete, conoscete sicuramente `schema.gov.it`, che è il catalogo delle ontologie, degli schemi di dati, dei vocabolari controllati. È chiaro che è un lavoro in progress, per cui non ci sono al momento ontologie per tutte le tipologie di dati, quindi man mano sta crescendo e quello è uno strumento, per esempio, che può essere utile come base, come supporto per strumenti per la misurazione della qualità.

Quindi, in genere, una delle critiche per le linee guida è che non sono obbligatorie. La sezione sulla qualità non è obbligatoria. Diciamo che in parte è voluta proprio per questo, perché se non dai strumenti alle amministrazioni su come misurare questa qualità, è chiaro che non puoi pretendere che l'amministrazione... ovviamente devi pretendere che lo faccia, ma che sia un percorso che poi arrivi anche all'obbligo. Questo che vuol dire? Che dall'anno scorso abbiamo cominciato a inserire sul Piano Triennale la conformità a queste caratteristiche di qualità. Nel senso, abbiamo iniziato dalla più facile, diciamo, che è l'attualità, l'aggiornamento dei dati. Come sapete, nei metadati si può indicare la frequenza di aggiornamento, si può indicare la data di ultima modifica. È chiaro che se queste due informazioni non 'matchano', perché se ho messo che è mensile, però ho una data di ultima modifica di un anno fa, è chiaro che il dato non è aggiornato. Quindi l'anno scorso l'abbiamo inserita e quindi dall'anno scorso cominciamo a misurare. Ovviamente lo possiamo fare sulla base dei dati documentati su `dati.gov.it`, non abbiamo altri strumenti per il momento. E ovviamente i dati documentati su `dati.gov.it` non sono tutti i dati della pubblica amministrazione, ma sono una piccolissima parte di tutti i dati. Noi 'arvestiamo' quelli. Tutto il patrimonio della pubblica amministrazione non lo conosciamo. Lo dicevo forse un'altra volta, qualcuno ci chiedeva: 'Ma perché non mettiamo la percentuale di dati aperti rispetto ai dati totali?'. I dati totali chi li conosce? E quindi non possiamo farlo.

Quindi questo per dire: le linee guida Open Data hanno definito, se volete, un modello di qualità che sono quattro caratteristiche delle 15 definite dall'ISO 25012. Poi, in aggiunta, io ho messo accessibilità e riservatezza, perché queste sono due caratteristiche di qualità che derivano da norme obbligatorie: l'accessibilità per la Legge Stanca (e quindi tutte le regole che sono succedute, diciamo, alla Legge Stanca) e la riservatezza per il GDPR. Quindi quelle due, anche se non sono indicate esplicitamente nel modello di qualità, ma questo è scritto anche nelle linee guida, è chiaro che sono automaticamente da garantire, perché ci sono altre norme che lo dicono.

Nelle linee guida sull'intelligenza artificiale, che abbiamo fatto un po' come il regolamento sui dati di elevato valore, non è che abbiamo buttato le regole che c'erano prima, e quindi abbiamo costruito e definito altre regole. Abbiamo detto: 'Tutte le regole che ci sono su Open Data, ma anche su dati che non siano Open Data, vanno seguite'. Ovviamente, per quanto riguarda la qualità, abbiamo integrato il modello di qualità con altre caratteristiche che possono essere utili nell'ambito dei sistemi di intelligenza artificiale. Quindi diciamo è un modello esteso rispetto a quello delle linee guida Open Data, chiaramente facendo riferimento poi ai requisiti dell'AI Act. Per questo io li ho riportati: chiaramente, tutti questi poi vengono rappresentati da quelle caratteristiche di qualità che sono degli standard ISO. Perché qua il 25012 è stato aggiunto il 25059, che è quello specifico per la misura di qualità per l'intelligenza artificiale.

La stessa cosa sul processo di gestione dei dati. C'è il rischio, e poi lo dirò anche dopo, che si creino nelle pubbliche amministrazioni tante strutture, per cui io ho la struttura che si occupa di Open Data, ho la struttura che si occupa dei dati territoriali, ho la struttura che adesso si deve occupare dei dati per l'intelligenza artificiale... Così come i processi: quando c'è – perché non è detto che ci sia – un processo di gestione dei dati, c'è il rischio che si facciano processi diversi e che non ci sia una gestione unitaria e complessiva dei dati a livello di amministrazione. Allora, siccome avevamo già definito un processo di gestione dati nelle linee guida Open Data, abbiamo analizzato gli aspetti di governance e gestione che sono riportati all'articolo 10 delle regole sull'intelligenza artificiale, abbiamo analizzato il ciclo di vita del dato così come definito dagli standard ISO e abbiamo cercato, abbiamo definito un processo di gestione dei dati che sia unitario. Cioè, ci sono alcune fasi che non sono specifiche per Open Data o per dati per l'intelligenza artificiale, ma sono comuni a tutti. Per cui, perché io devo avviare processi diversi quando ovviamente devo e posso ottimizzare, anche perché poi le risorse non sono infinite (per chi è nella pubblica amministrazione soprattutto, lo sa)? Perché devo avviare diversi processi con il rischio che magari il dato creato da un certo dipartimento di un'amministrazione poi non possa essere riutilizzato da un'altra, perché magari, e questo avviene, seguono anche standard diversi? Per cui abbiamo rivisto, diciamo, il processo di gestione dati, integrandolo ovviamente con alcune attività specifiche per i dati nell'ambito dei sistemi di intelligenza artificiale.

(Antonio, c'è un motivo per cui hai scelto dei colori diversi per alcuni blocchi?)
Perché quelli grigi sono specifici per l'intelligenza artificiale, quindi sono operazioni che vengono richieste per dati che possono essere utilizzati per l'addestramento di sistemi di intelligenza artificiale. Cioè, l'analisi della qualità io non la devo fare solo per i dati dell'intelligenza artificiale, la devo fare per gli Open Data, la devo fare per i dati territoriali, la devo fare per tutte le tipologie di dati. Così come la pianificazione e raccolta. Anzi, in fase di pianificazione io posso lì, sulla base dei requisiti che ho, delle esigenze, definire quali dati produrre e quindi rendere come Open Data, che comunque possono essere utilizzati anche nell'ambito dell'intelligenza artificiale, e quant'altro.

E chiaramente questo lo riporto perché tra le attività che AgID fa, abbiamo detto, ci sono le regole tecniche, però voi sapete che gestisce anche due portali nazionali di dati. E quello che ormai dico spesso, anche soprattutto ultimamente, è che non è sufficiente rendere disponibili i dati, è necessario anche farli conoscere. Cioè, l'utente, se tu pubblichi un dato, come fa a saperlo se non va a girare tutti i siti delle pubbliche amministrazioni? Vediamo, se la pubblica amministrazione... c'è uno strumento che è il catalogo dei dati, che serve proprio a quello: evitare all'utente di girare 10.000 siti delle pubbliche amministrazioni. È chiaro che per fare questo, e perché sia, diciamo, utile, le pubbliche amministrazioni devono documentare i propri dati in questi cataloghi. Chiaramente, anche qui, è un lavoro in progress. Poi si amplifica comunque la conoscibilità, perché poi da questi portali nazionali vengono pubblicati sul portale europeo o sui portali europei (c'è pure il geoportale Inspire) e quindi l'utente, a prescindere dal punto di avvio della ricerca, perché uno può anche non conoscere il repertorio, può anche non conoscere `dati.gov.it`, magari si imbatte nell'European Data Portal e da lì riesce ad arrivare al dato. Così, viceversa, io da `dati.gov.it` posso arrivare a un dato geografico perché è anche aperto ed è documentato in entrambi i cataloghi.

Velocemente, scusate qualche minuto. Lo dicevo all'inizio: il Data Governance Act si riferisce a tutti gli altri dati che non possono essere aperti. Come dicevo, AgID è stata individuata come autorità nazionale per tutti i compiti previsti nel Data Governance Act. Gli aspetti coperti dal Governance Act, li citavo prima, sono il riutilizzo di dati protetti (quindi tutti quei dati della pubblica amministrazione che non possono essere pubblicati come dati aperti devono comunque essere resi disponibili, ovviamente in ambiente sicuro, eccetera, eccetera, anonimizzati quando serve, eccetera, però devono essere resi disponibili). È chiaro che in questo caso non sono resi disponibili a tutti, ma a utenti conosciuti. Anche per questi dati, su `dati.gov.it` ci sarà una sezione dedicata, così come c'è attualmente sul portale europeo, perché viene richiesto proprio che nel Data Governance Act ci sia uno sportello unico in cui l'utente possa andare a vedere quali dati sono disponibili, anche se, ovviamente, a differenza degli Open Data, non li può scaricare. Quindi va a vedere quali dati sono disponibili, anche protetti, e quindi poi, se gli serve uno di questi dati protetti, può rivolgersi all'amministrazione che ne è titolare.

L'intermediazione di dati: tutti i dati, anche delle imprese, possono essere comunque resi disponibili e viene introdotta proprio la figura del fornitore di servizi di intermediazione, cioè proprio una figura intermedia che fa da tramite tra chi produce il dato e chi lo vuole riutilizzare. Si parla di un vero e proprio marketplace dei dati, quindi ovviamente deve guadagnare l'intermediario e quindi si crea anche un mercato. Questo consente anche alle piccole aziende... adesso soprattutto i grandi player utilizzano e hanno la forza, diciamo, di riutilizzare i dati. In questo caso anche le piccole aziende possono intervenire in questo processo.

E poi c'è il principio, diciamo bellissimo, dell'altruismo dei dati, che però non so quanto sarà applicato. Cioè, noi lo stiamo applicando come Open Data Sicilia, attivisti, persone... comunque ci sono, intendo anche te, come organizzazioni che non sono obbligate per legge, per norma, a rendere disponibili dati, che, diciamo, a livello volontaristico rendono disponibili comunque i dati. A livello europeo, al momento, una sola organizzazione si è registrata (perché bisogna registrarsi in Italia, presso AgID) e solo un'organizzazione si è registrata come 'organizzazione per l'altruismo dei dati'.

Finisco dicendo che avevo citato pure i data space, quindi gli spazi di dati, che sono ecosistemi, diciamo, in cui intervengono diversi attori e sono stati individuati 14 spazi di dati: agricoltura, pubblica amministrazione, dati sanitari, eccetera. Il primo, diciamo, spazio di dati su cui è stato adottato un regolamento, quindi delle regole, delle norme vere e proprie, è il regolamento dello Spazio Europeo dei Dati Sanitari. Questo ha una forte connessione con il Data Governance Act e lì c'è un esempio. Per esempio, si prevede un catalogo dei dati. Ovviamente, i dati sanitari non possono essere utilizzati da tutti, ma ci sono utilizzi primari (quindi tra strutture sanitarie, per esempio, che utilizzano i dati di altre strutture sanitarie) o un utilizzo secondario, cioè dati che possono essere utilizzati anche da altri utenti in generale e che li utilizzano per altri scopi, anche di ricerca, di analisi, eccetera. È previsto un catalogo. Questo catalogo, ovviamente, dovrà essere in relazione con quello che è lo sportello unico che sarà presente su `dati.gov.it`. Come vedete, tutto è collegato e tutto si tiene.

Chiaramente, quell'esigenza che dicevo all'inizio, cioè l'esigenza di avere dati affidabili, sicuri, ben organizzati, di qualità, è un'esigenza chiaramente a livello europeo, tanto che nella seconda metà del 2025 è prevista una nuova strategia sui dati dell'Unione che possa garantire e accelerare parecchio questa, diciamo, attività sulla qualità dei dati. Fino al 18 luglio, se volete, c'è una consultazione pubblica (poi c'è il link, diciamo, sulla slide): si possono, chiaramente, fornire osservazioni e indicazioni su che cosa ci si aspetterebbe da una strategia dei dati dell'Unione Europea, ovviamente ai fini della disponibilità dei dati per l'intelligenza artificiale. Grazie.